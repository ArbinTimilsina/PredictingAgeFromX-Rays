{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "929690ea-c756-459b-8445-eab180b1bd55",
    "_uuid": "2056f822c8514fd29db2073ab0643e8adeb5c098"
   },
   "source": [
    "# Predicting Age From X-Rays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Develop an algorithm to determine the age of a child by utilizing x-rays of hands (pediatric hand radiographs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common variables for all models\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau    \n",
    "\n",
    "epochs = 250\n",
    "\n",
    "batchSize = 20\n",
    "imageLength = 224\n",
    "imageHeight = 224\n",
    "\n",
    "# Stop training when a monitored quantity has stopped improving after 25 epochs\n",
    "earlyStop = EarlyStopping(patience=25, verbose=1)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduceLR = ReduceLROnPlateau(factor=0.3, patience=3, cooldown=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12611 total data samples.\n",
      "('\\nData type for each column is:\\n', id         int64\n",
      "boneage    int64\n",
      "male        bool\n",
      "dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377</td>\n",
       "      <td>180</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1378</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1379</td>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1380</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1381</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  boneage   male\n",
       "0  1377      180  False\n",
       "1  1378       12  False\n",
       "2  1379       94  False\n",
       "3  1380      120   True\n",
       "4  1381       82  False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# CSV file contains the id, age, and gender related to each x-ray\n",
    "dataset = pd.read_csv(\"Input/boneage-dataset.csv\")\n",
    "\n",
    "# Dropping all rows with any NA values\n",
    "dataset.dropna()\n",
    "\n",
    "print('There are %d total data samples.' % dataset.shape[0])\n",
    "print('\\nData type for each column is:\\n',dataset.dtypes)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the x-ray images to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Awesome!! All', 12611, 'x-ray images found out of', 12611, 'total!')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset['image_path'] = dataset['id'].map(lambda x: os.path.join('Input/boneage-dataset', '{}.png'.format(x)))\n",
    "\n",
    "if dataset['image_path'].map(os.path.exists).sum() != dataset.shape[0]:\n",
    "    print('Warning!! Only', dataset['image_path'].map(os.path.exists).sum(), \n",
    "          'x-ray images found out of', dataset.shape[0], 'total! \\nWill continue with reduced dataset!!')\n",
    "    dataset = dataset[dataset['image_path'].map(os.path.exists)]\n",
    "else:\n",
    "    print('Awesome!! All',dataset['image_path'].map(os.path.exists).sum(), \n",
    "          'x-ray images found out of', dataset.shape[0], 'total!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in a stratified fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['1.0-69.0', '69.0-94.0', '94.0-106.0', '106.0-120.0', '120.0-132.0', '132.0-144.0', '144.0-156.0', '156.0-162.0', '162.0-168.0', '168.0-228.0'], '\\n')\n",
      "     id  boneage   male                      image_path boneage_category\n",
      "0  1377      180  False  Input/boneage-dataset/1377.png      168.0-228.0\n",
      "1  1378       12  False  Input/boneage-dataset/1378.png         1.0-69.0\n",
      "2  1379       94  False  Input/boneage-dataset/1379.png        69.0-94.0\n",
      "3  1380      120   True  Input/boneage-dataset/1380.png      106.0-120.0\n",
      "4  1381       82  False  Input/boneage-dataset/1381.png        69.0-94.0\n"
     ]
    }
   ],
   "source": [
    "# Make new colum 'boneage_category' such that each category has the same number of samples\n",
    "deciles_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "deciles = dataset['boneage'].quantile(q=deciles_list)\n",
    "\n",
    "deciles_labels =[]\n",
    "for i in range(deciles.size):\n",
    "    if i==deciles.size-1: continue\n",
    "    deciles_labels.append(str(deciles[deciles.index[i]])+'-'+str(deciles[deciles.index[i+1]]))   \n",
    "print(deciles_labels, '\\n')\n",
    "    \n",
    "dataset['boneage_category'] = pd.qcut(dataset['boneage'], q=deciles_list, labels=deciles_labels)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training, testing, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has a training set of 7093 examples.\n",
      "The dataset has a test set of 3153 examples.\n",
      "The dataset has a validation set of 2365 examples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_train, dataset_test = train_test_split(dataset, test_size=0.25, random_state=99, \n",
    "                                                    stratify=dataset['boneage_category'])\n",
    "dataset_train, dataset_val  = train_test_split(dataset_train, test_size=0.25, random_state=99,\n",
    "                                                    stratify=dataset_train['boneage_category'])\n",
    "                                                                    \n",
    "print(\"The dataset has a training set of %d examples.\" % len(dataset_train))\n",
    "print(\"The dataset has a test set of %d examples.\" % len(dataset_test))\n",
    "print(\"The dataset has a validation set of %d examples.\" % len(dataset_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and configure augmented image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute '_set_index_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b69f12406e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_index_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute '_set_index_array'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    width_shift_range=0.1,    # Fraction of total width for random horizontal shifts\n",
    "    height_shift_range=0.1,   # Fraction of total height for random vertical shifts\n",
    "    rotation_range = 5,        # Degree range for random rotations\n",
    "    horizontal_flip=True)      # Randomly flip images horizontally\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator_train = datagen_train.flow_from_directory(\n",
    "        os.path.dirname(dataset_train['image_path'].values[0]),  # this is the target directory\n",
    "        target_size=(imageLength, imageHeight),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='sparse')\n",
    "generator_train.filenames = dataset_train['image_path'].values\n",
    "generator_train.classes = np.stack(dataset_train['boneage'].values)\n",
    "generator_train.samples = dataset_train.shape[0]\n",
    "generator_train.n = dataset_train.shape[0]\n",
    "generator_train._set_index_array()\n",
    "generator_train.directory = ''\n",
    "\n",
    "generator_val = datagen_val.flow_from_directory(\n",
    "        os.path.dirname(dataset_val['image_path'].values[0]),  # this is the target directory\n",
    "        target_size=(imageLength, imageHeight),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='sparse')\n",
    "generator_val.filenames = dataset_val['image_path'].values\n",
    "generator_val.classes = np.stack(dataset_val['boneage'].values)\n",
    "generator_val.samples = dataset_val.shape[0]\n",
    "generator_val.n = dataset_val.shape[0]\n",
    "#generator_val._set_index_array()\n",
    "generator_val.directory = ''\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(\n",
    "        os.path.dirname(dataset_test['image_path'].values[0]),  # this is the target directory\n",
    "        target_size=(imageLength, imageHeight),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='sparse')\n",
    "generator_test.filenames = dataset_test['image_path'].values\n",
    "generator_test.classes = np.stack(dataset_test['boneage'].values)\n",
    "generator_test.samples = dataset_test.shape[0]\n",
    "generator_test.n = dataset_test.shape[0]\n",
    "#generator_test._set_index_array()\n",
    "generator_test.directory = ''\n",
    "\n",
    "X_train, y_train = next(generator_train)\n",
    "#X_test, y_test = next(generator_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize original and augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "benchmarkModel = Sequential()\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu',\n",
    "                          input_shape=(imageLength, imageHeight, 3)))\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.5))\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.5))\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.5))\n",
    "\n",
    "benchmarkModel.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "benchmarkModel.add(MaxPooling2D(pool_size=2))\n",
    "benchmarkModel.add(Dropout(0.5))\n",
    "\n",
    "benchmarkModel.add(Flatten())         \n",
    "benchmarkModel.add(Dense(500, activation='relu'))\n",
    "benchmarkModel.add(Dropout(0.5))\n",
    "\n",
    "benchmarkModel.add(Dense(229, activation='softmax'))\n",
    "\n",
    "benchmarkModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarkModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the classification accuracy of the benchmark model (before training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the test accuracy\n",
    "accuracy = benchmarkModel.predict_generator(generator_test, 10)\n",
    "#accuracy = 100*score[1]\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy of the benchmark model (before training): %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint    \n",
    "\n",
    "# Save the best model after every epoch\n",
    "checkPoint = ModelCheckpoint(filepath='SavedModels/BenchmarkBest.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "# Fit the model on batches with real-time data augmentation:\n",
    "history = benchmarkModel.fit_generator(generator_train,\n",
    "                                       steps_per_epoch=dataset_train.shape[0] // batchSize, epochs=epochs, \n",
    "                                       validation_data=generator_val, validation_steps=dataset_val.shape[0] // batchSize,\n",
    "                                       callbacks=[checkPoint, earlyStop, reduceLR], verbose=0)\n",
    "# List all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Benchmark model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/BenchmarkAccuracy.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Benchmark model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('Plots/BenchmarkLoss.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the classification accuracy of the benchmark model (after training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best classification accuracy on the validation set\n",
    "benchmarkModel.load_weights('SavedModels/BenchmarkBest.hdf5')\n",
    "\n",
    "# Calculate the classification accuracy on the test set\n",
    "score = benchmarkModel.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Print the test accuracy\n",
    "print('Test accuracy of the benchmark model (after training): %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result of the benchmark model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = benchmarkModel.predict(X_test, verbose = False)\n",
    "\n",
    "y_p = []\n",
    "for y in y_pred:\n",
    "    y_p.append(np.argmax(y))\n",
    "y_t = []\n",
    "for t in y_test:\n",
    "    y_t.append(np.argmax(t))\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (6,6))\n",
    "ax1.plot(y_t, y_t, 'b-', label = 'True')\n",
    "ax1.plot(y_t, y_p, 'r.', label = 'Predictions')\n",
    "ax1.legend()\n",
    "ax1.set_title('Benchmark model', fontsize=25)\n",
    "ax1.set_xlabel('True Age (Months)', fontsize=20)\n",
    "ax1.set_ylabel('Predicted Age (Months)', fontsize=20)\n",
    "pt.setTicks(ax1)\n",
    "\n",
    "fig.savefig('Plots/BenchmarkResult.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
